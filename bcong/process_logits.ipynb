{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b0bc986e-574a-4fe7-b688-03d60f95037c",
      "metadata": {
        "id": "b0bc986e-574a-4fe7-b688-03d60f95037c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import transformers\n",
        "import pickle as pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "31769cfb-71fc-4b20-95ca-d50d5cfc4c68",
      "metadata": {
        "id": "31769cfb-71fc-4b20-95ca-d50d5cfc4c68"
      },
      "outputs": [],
      "source": [
        "ce_loss_fn = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
        "softmax_fn = torch.nn.Softmax(dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a69ea5c5-659a-4bb3-a61f-2650d3597f06",
      "metadata": {
        "id": "a69ea5c5-659a-4bb3-a61f-2650d3597f06"
      },
      "outputs": [],
      "source": [
        "encodings = pkl.load(open(\"encodings.pkl\", 'rb'))\n",
        "observer_logits = pkl.load(open(\"ob_logits.pkl\", 'rb'))\n",
        "performer_logits = pkl.load(open(\"pf_logits.pkl\", 'rb'))\n",
        "pad_token = pkl.load(open(\"pad_token_id.pkl\", 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ab2c7dcb-85be-4226-9356-9c022406a6f4",
      "metadata": {
        "id": "ab2c7dcb-85be-4226-9356-9c022406a6f4"
      },
      "outputs": [],
      "source": [
        "np.set_printoptions(formatter={'float_kind':'{:f}'.format})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "8c7c02d1-ebdc-4b89-a2b2-f2639ba0d2e9",
      "metadata": {
        "id": "8c7c02d1-ebdc-4b89-a2b2-f2639ba0d2e9"
      },
      "outputs": [],
      "source": [
        "def perplexity(encoding: transformers.BatchEncoding,\n",
        "               logits: torch.Tensor,\n",
        "               median: bool = False,\n",
        "               temperature: float = 1.0):\n",
        "    shifted_logits = logits[..., :-1, :].contiguous() / temperature\n",
        "    # print(shifted_logits)\n",
        "    shifted_labels = encoding.input_ids[..., 1:].contiguous()\n",
        "    # print(shifted_labels)\n",
        "    shifted_attention_mask = encoding.attention_mask[..., 1:].contiguous()\n",
        "    # print(shifted_attention_mask)\n",
        "    if median:\n",
        "        ce_nan = (ce_loss_fn(shifted_logits.transpose(1, 2), shifted_labels).\n",
        "                  masked_fill(~shifted_attention_mask.bool(), float(\"nan\")))\n",
        "        # print(ce_nan)\n",
        "        walk = ce_nan.to(\"cpu\").float().numpy()\n",
        "        # print(walk)\n",
        "        ppl = np.nanmedian(ce_nan.cpu().float().numpy(), 1)\n",
        "\n",
        "    else:\n",
        "        ppl = (ce_loss_fn(shifted_logits.transpose(1, 2), shifted_labels) *\n",
        "               shifted_attention_mask).sum(1) / shifted_attention_mask.sum(1)\n",
        "        ppl = ppl.to(\"cpu\").float().numpy()\n",
        "\n",
        "    return ppl, walk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "b9663b8d-98fd-4cae-a951-1bf4a0e939af",
      "metadata": {
        "id": "b9663b8d-98fd-4cae-a951-1bf4a0e939af",
        "outputId": "969d519f-60ed-47d0-d8c6-416f1e59fe62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Dr.', 0.6953125), ('Capy', 9.8125), ('Cosmos,', 6.03125), ('a', 9.75), ('capybara', 1.84375), ('unlike', 2.984375), ('any', 1.921875), ('other,', 6.9375), ('astounded', 0.040771484), ('the', 0.026123047), ('scientific', 11.5), ('community', 0.27734375), ('with', 0.140625), ('his', 0.3046875), ('groundbreaking', 9.0625), ('research', 1.765625), ('in', 1.1171875), ('astrophysics.', 2.4375), ('With', 0.71484375), ('his', 1.0859375), ('keen', 1.4296875), ('sense', 8.125), ('of', 5.90625), ('observation', 0.5859375), ('and', 1.703125), ('unparalleled', 2.34375), ('ability', 1.84375), ('to', 0.51171875), ('interpret', 0.31640625), ('cosmic', 3.34375), ('data,', 1.4609375), ('he', 3.03125), ('uncovered', 2.46875), ('new', 0.048828125), ('insights', 3.328125), ('into', 1.1640625), ('the', 4.4375), ('mysteries', 4.03125), ('of', 0.30859375), ('black', 5.59375), ('holes', 2.984375), ('and', 3.515625), ('the', 0.04296875), ('origins', 2.4375), ('of', 0.08886719), ('the', 1.6328125), ('universe.', 3.828125), ('As', 4.4375), ('he', 1.046875), ('peered', 0.67578125), ('through', 0.20214844), ('telescopes', 3.46875), ('with', 0.053955078), ('his', 3.546875), ('large,', 0.009460449), ('round', 0.55859375), ('eyes,', 0.703125), ('fellow', 2.078125), ('researchers', 0.011230469), ('often', 0.1875), ('remarked', 0.034423828), ('that', 0.2734375), ('it', 3.703125), ('seemed', 2.625), ('as', 0.4375), ('if', 7.28125), ('the', 0.25390625), ('stars', 1.1640625), ('themselves', 3.765625), ('whispered', 0.19628906), ('their', 3.515625), ('secrets', 0.88671875), ('directly', 3.28125), ('to', 0.48632812), ('him.', 2.40625), ('Dr.', 0.095703125), ('Cosmos', 0.09082031), ('not', 8.75), ('only', 2.28125), ('became', 4.4375), ('a', 2.453125), ('beacon', 1.390625), ('of', 2.59375), ('inspiration', 1.859375), ('to', 0.99609375), ('aspiring', 0.24804688), ('scientists', 1.9921875), ('but', 0.25195312), ('also', 1.46875), ('proved', 0.625), ('that', 5.625), ('intellect', 2.28125), ('and', 0.025756836), ('innovation', 4.5625), ('can', 0.1328125), ('be', 0.26757812), ('found', 0.0390625), ('in', 2.65625), ('the', 0.010314941), ('most', 0.2109375), ('unexpected', 0.0050354004), ('of', 6.21875), ('creatures.', 0.009643555)]\n",
            "103\n"
          ]
        }
      ],
      "source": [
        "# print(perplexity(encodings, observer_logits, median=True))\n",
        "# print(perplexity(encodings, performer_logits, median=True))\n",
        "# ob_ppl, ob_walk = perplexity(encodings, observer_logits, median=True)\n",
        "pf_ppl, pf_walk = perplexity(encodings, performer_logits, median=True)\n",
        "sample_string = '''Dr. Capy Cosmos, a capybara unlike any other, astounded the scientific community with his\n",
        "groundbreaking research in astrophysics. With his keen sense of observation and unparalleled ability to interpret\n",
        "cosmic data, he uncovered new insights into the mysteries of black holes and the origins of the universe. As he\n",
        "peered through telescopes with his large, round eyes, fellow researchers often remarked that it seemed as if the\n",
        "stars themselves whispered their secrets directly to him. Dr. Cosmos not only became a beacon of inspiration to\n",
        "aspiring scientists but also proved that intellect and innovation can be found in the most unexpected of creatures.'''\n",
        "# ob_ppl_list = [(word, ob_walk[0][w]) for w, word in enumerate(sample_string.split())]\n",
        "pf_ppl_list = [(word, pf_walk[0][w]) for w, word in enumerate(sample_string.split())]\n",
        "# print(ob_ppl_list)\n",
        "print(pf_ppl_list)\n",
        "print(len(pf_ppl_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "5fff1d0e-c5f0-4859-87df-190fe3d8e4c4",
      "metadata": {
        "id": "5fff1d0e-c5f0-4859-87df-190fe3d8e4c4"
      },
      "outputs": [],
      "source": [
        "def entropy(p_logits: torch.Tensor,\n",
        "            q_logits: torch.Tensor,\n",
        "            encoding: transformers.BatchEncoding,\n",
        "            pad_token_id: int,\n",
        "            median: bool = False,\n",
        "            sample_p: bool = False,\n",
        "            temperature: float = 1.0):\n",
        "    vocab_size = p_logits.shape[-1]\n",
        "    total_tokens_available = q_logits.shape[-2]\n",
        "    p_scores, q_scores = p_logits / temperature, q_logits / temperature\n",
        "\n",
        "    p_proba = softmax_fn(p_scores).view(-1, vocab_size)\n",
        "\n",
        "    if sample_p:\n",
        "        p_proba = torch.multinomial(p_proba.view(-1, vocab_size), replacement=True, num_samples=1).view(-1)\n",
        "\n",
        "    q_scores = q_scores.view(-1, vocab_size)\n",
        "\n",
        "    ce = ce_loss_fn(input=q_scores, target=p_proba).view(-1, total_tokens_available)\n",
        "    padding_mask = (encoding.input_ids != pad_token_id).type(torch.uint8)\n",
        "\n",
        "    if median:\n",
        "        ce_nan = ce.masked_fill(~padding_mask.bool(), float(\"nan\"))\n",
        "        en_walk = ce_nan.to(\"cpu\").float().numpy()\n",
        "        agg_ce = np.nanmedian(ce_nan.cpu().float().numpy(), 1)\n",
        "        return agg_ce, en_walk\n",
        "    else:\n",
        "        agg_ce = (((ce * padding_mask).sum(1) / padding_mask.sum(1)).to(\"cpu\").float().numpy())\n",
        "\n",
        "    return agg_ce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "61e54747-1395-4909-ad6b-47725f899c77",
      "metadata": {
        "id": "61e54747-1395-4909-ad6b-47725f899c77",
        "outputId": "fc7f98df-512a-44a0-c752-e687b594a969",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3.125000 7.343750 5.187500 7.468750 3.937500 5.031250 6.218750 7.125000\n",
            "  0.281250 0.247070 4.468750 1.210938 0.914062 1.679688 4.468750 1.828125\n",
            "  4.062500 4.687500 1.015625 2.765625 1.953125 6.031250 6.312500 0.882812\n",
            "  4.125000 2.812500 4.843750 1.648438 1.875000 4.625000 3.593750 7.562500\n",
            "  4.093750 0.488281 5.281250 1.226562 6.031250 4.093750 0.875000 6.062500\n",
            "  4.125000 4.562500 0.671875 4.281250 0.824219 2.015625 4.656250 3.953125\n",
            "  4.562500 1.656250 1.914062 4.625000 0.277344 1.789062 0.285156 1.382812\n",
            "  4.375000 5.500000 0.077148 1.250000 0.863281 0.792969 2.875000 2.796875\n",
            "  3.812500 5.437500 3.171875 2.031250 1.453125 0.225586 2.734375 3.812500\n",
            "  7.187500 2.546875 6.000000 1.875000 0.992188 2.859375 2.296875 5.125000\n",
            "  5.343750 2.359375 2.531250 1.804688 2.265625 1.062500 2.234375 1.546875\n",
            "  5.281250 2.421875 1.781250 3.437500 1.210938 1.546875 1.156250 1.429688\n",
            "  0.609375 3.406250 0.036133 0.691406 0.019409 4.500000 0.117188 6.062500\n",
            "  2.484375 4.875000 0.964844 3.531250 1.718750 1.445312 3.890625 0.039307\n",
            "  2.953125 2.421875 2.375000 4.125000 2.312500 5.125000 2.375000 6.218750\n",
            "  3.093750 3.937500 3.796875 2.203125 3.421875 3.140625 1.789062 1.562500\n",
            "  1.710938 0.507812 1.351562]]\n"
          ]
        }
      ],
      "source": [
        "# original\n",
        "# ppl = perplexity(encodings, performer_logits)\n",
        "# x_ppl = entropy(observer_logits.to(DEVICE_1), performer_logits.to(DEVICE_1),\n",
        "#                 encodings.to(DEVICE_1), self.tokenizer.pad_token_id)\n",
        "x_ppl, en_walk = entropy(observer_logits, performer_logits, encodings, pad_token, median=True)\n",
        "pkl.dump(en_walk, open('en_walk.pkl', 'wb'))\n",
        "print(en_walk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "abe5d33f-8c36-43b3-8caa-af250d005cf8",
      "metadata": {
        "id": "abe5d33f-8c36-43b3-8caa-af250d005cf8"
      },
      "outputs": [],
      "source": [
        "bino_walk = (pf_walk / en_walk[..., 1:])\n",
        "pkl.dump(bino_walk, open(\"bino_walk\", 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(bino_walk)"
      ],
      "metadata": {
        "id": "mPAis61v0dg9",
        "outputId": "112475fa-2359-41b3-d2cb-27f9b68d08d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "mPAis61v0dg9",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.094681 1.891566 0.807531 2.476191 0.366460 0.479899 0.269737\n",
            "  24.666666 0.165020 0.005846 9.496774 0.303419 0.083721 0.068182\n",
            "  4.957265 0.434615 0.238333 2.400000 0.258475 0.556000 0.237047 1.287129\n",
            "  6.690266 0.142045 0.605556 0.483871 1.118483 0.272917 0.068412 0.930435\n",
            "  0.193182 0.740458 5.056000 0.009246 2.713376 0.193005 1.083969 4.607143\n",
            "  0.050902 1.356061 0.654110 5.232558 0.010036 2.957346 0.044089 0.350671\n",
            "  0.968379 0.972603 0.632075 0.353061 0.043708 12.507042 0.030158\n",
            "  12.438356 0.006841 0.127679 0.127841 26.936708 0.008984 0.217195\n",
            "  0.043411 0.095109 1.324022 0.688525 0.080460 2.295567 0.125000 0.801075\n",
            "  16.692640 0.071786 0.922131 0.123370 1.288344 0.081055 1.283333\n",
            "  0.096457 0.031762 3.809524 0.445122 0.830409 1.039735 0.549383 1.437229\n",
            "  0.820690 0.937500 0.111014 1.287879 0.047707 0.606452 0.350877 1.636364\n",
            "  1.883871 0.016651 3.945946 0.092896 0.439103 0.011468 73.513512\n",
            "  0.014919 10.867925 0.001119 53.066666 0.001591 1.226415 0.169071\n",
            "  4.307693 0.054204 3.254545 1.367568 0.173695 175.701859 0.003865\n",
            "  0.309677 0.756579 0.088068 2.500000 0.182165 3.842105 0.115578 2.090909\n",
            "  0.213294 0.413580 0.048759 0.149543 0.233831 0.086790 0.540000 0.803653\n",
            "  6.923077 0.042991]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tEbvY38v0wpr"
      },
      "id": "tEbvY38v0wpr",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}